# -*- coding: utf-8 -*-
"""My_project.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1W6yyfoKHyvudriblPDWUcAAkxfr2PYxT
"""

import pandas as pd
# import plotly.express as px
import numpy as np

df = pd.read_csv(r'C:\Users\Mary\Desktop\Project\fraud test.csv')
df.head()

df = df.sort_values(by = 'is_fraud', ascending=False)

df = df.head(20000)
df.to_csv('fraud test.csv')
df.head()

df.shape

df.info()

df.describe()

df.duplicated().sum()

df['is_fraud'].value_counts()

# df_new['is_fraud'].value_counts().plot(kind='bar')

print(df.head(1))

# from datetime import datetime
# # # import plotly.express as px

# datetime.now()
# pd.Timestamp.now()

df['dob'] = pd.to_datetime(df['dob'], format='mixed')

df['Age'] = (pd.Timestamp.now() - df['dob']).dt.days / 365

# df_new['Age']

df.head()

pd.set_option('display.max_columns', 100)

df.head()

# df_new['trans_date_trans_time'] = pd.to_datetime(df_new['trans_date_trans_time'])
# df_new['year'] = df_new['trans_date_trans_time'].dt.year
# df_new['month'] = df_new['trans_date_trans_time'].dt.month
# df_new['day'] = df_new['trans_date_trans_time'].dt.day
# df_new['hour'] = df_new['trans_date_trans_time'].dt.hour
# df_new['minute'] = df_new['trans_date_trans_time'].dt.minute
# df_new['second'] = df_new['trans_date_trans_time'].dt.second
# df_new['day_of_week'] = df_new['trans_date_trans_time'].dt.dayofweek
# df_new['day_of_year'] = df_new['trans_date_trans_time'].dt.dayofyear
# df_new['weekend'] = df_new['day_of_week'].apply(lambda x: 1 if x >= 5 else 0)
# df_new['quarter'] = df_new['trans_date_trans_time'].dt.quarter

df.head()

df.columns

df.drop(['trans_date_trans_time', 'Unnamed: 0', 'cc_num', 'first', 'last', 'street', 'city_pop', 'dob', 'trans_num', 'unix_time', 'zip'], axis=1, inplace=True)

df.head(2)

df.to_csv('fraud_detection.csv.cleaned', index=False)

df.select_dtypes('number').columns

# px.violin(df_new['amt'])

# df_new.rename(columns={'year':'year_of_trans'}, inplace=True)
# df_new.rename(columns={'month':'month_of_trans'}, inplace=True)
# df_new.rename(columns={'day':'day_of_trans'}, inplace=True)
# df_new.rename(columns={'hour':'hour_of_trans'}, inplace=True)
# df_new.rename(columns={'minute':'minute_of_trans'}, inplace=True)
# df_new.rename(columns={'second':'second_of_trans'}, inplace=True)
# df_new.rename(columns={'day_of_week':'day_of_week_of_trans'}, inplace=True)
# df_new.rename(columns={'day_of_year':'day_of_year_of_trans'}, inplace=True)
# df_new.rename(columns={'weekend':'weekend_of_trans'}, inplace=True)
# df_new.rename(columns={'quarter':'quarter_of_trans'}, inplace=True)

# df_new.head(1)



# px.pie(df_new, names ='gender', values ='is_fraud', title='Gender vs Fraud')

# px.bar(df_new, x ='category', y ='is_fraud', title='Category vs Fraud')

# px.histogram(df_new, x ='Age', y ='is_fraud', title='Age vs Fraud')

# !pip install ydata_profiling
# from ydata_profiling import ProfileReport

# Cynthia_Project = ProfileReport(df_new, title = ' Project by CynTech')
# Cynthia_Project.to_notebook_iframe()

df.select_dtypes('object').columns

from sklearn.preprocessing import LabelEncoder
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler

merchant_encoder = LabelEncoder()
df['merchant'] = merchant_encoder.fit_transform(df['merchant'])

category_encoder = LabelEncoder()
df['category'] = category_encoder.fit_transform(df['category'])

gender_encoder = LabelEncoder()
df['gender'] = gender_encoder.fit_transform(df['gender'])

city_encoder = LabelEncoder()
df['city'] = city_encoder.fit_transform(df['city'])

state_encoder = LabelEncoder()
df['state'] = state_encoder.fit_transform(df['state'])

job_encoder = LabelEncoder()
df['job'] = job_encoder.fit_transform(df['job'])

df.head(1)


X = df.drop('is_fraud', axis=1)
y = df['is_fraud']

x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

sc = StandardScaler()

x_train = sc.fit_transform(x_train)
x_test = sc.transform(x_test)

from sklearn.metrics import accuracy_score, precision_score, f1_score, recall_score
from lightgbm import LGBMClassifier
from sklearn.svm import SVC
from sklearn.ensemble import RandomForestClassifier


model = LGBMClassifier(random_state = 42)
model.fit(x_train, y_train)
ypred = model.predict(x_test)
print('The accuracy for lightgbm is  :', accuracy_score(y_test,ypred))

model = RandomForestClassifier(random_state = 42)
model.fit(x_train, y_train)
ypred = model.predict(x_test)
print('The accuracy for random forest is  :', accuracy_score(y_test,ypred))

model = SVC(random_state = 42)
model.fit(x_train, y_train)
ypred = model.predict(x_test)
print('The accuracy for XGM is  :', accuracy_score(y_test,ypred))

models = [
    ('Lgbm', LGBMClassifier()),
    ('RandomForestClassifier', RandomForestClassifier()),
    ('Support Vector machine', SVC())
]

result = []

for name, model in models:
  model.fit(x_train,y_train)
  ypred = model.predict(x_test)


  accuracy = accuracy_score(y_test, ypred)
  precision = precision_score(y_test, ypred)
  f1 = f1_score(y_test, ypred)
  recall = recall_score(y_test, ypred)

  result.append({'model': name, 'accuracy_score': accuracy , 'precision_score': precision, 'F1_score': f1, 'Recall_score': recall})

results = pd.DataFrame(result)

results

import pickle


model = RandomForestClassifier(random_state = 42)
model.fit(x_train, y_train)


#Save the model to disk
with open('model.pkl', 'wb') as file:
    pickle.dump(model,file)

with open('scaler.pkl', 'wb') as file:
    pickle.dump(sc, file)

# saving Categorical columns to disk
with open('gender_encoder.pkl', 'wb') as file:
    pickle.dump(gender_encoder, file)

with open('category_encoder.pkl', 'wb') as file:
    pickle.dump(category_encoder,file)

with open('city_encoder.pkl', 'wb') as file:
    pickle.dump(city_encoder, file)

with open('state_encoder.pkl', 'wb') as file:
    pickle.dump(state_encoder, file)

with open('merchant_encoder.pkl', 'wb') as file:
    pickle.dump(merchant_encoder, file)

with open('job_encoder.pkl', 'wb') as file:
    pickle.dump(job_encoder, file)

print(X.columns)
print('Successfull')